{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Deepseek model works\n",
    "\n",
    "Checking how deepseek-r1 model works on local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"deepseek-r1:latest\", temperature=0)\n",
    "llm_json = ChatOllama(model=\"deepseek-r1:latest\", format=\"json\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n</think>\\n\\nThe capital of Poland is Warsaw.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = llm.invoke(\"What is capital of Poland?\")\n",
    "msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"What are the best ways to take care of a cat's health?\",\n",
       " 'aspect': 'cat health',\n",
       " 'rationale': \"The query 'What are the best ways to take care of a cat's health?' is designed to gather information related to the aspect of 'cat health'. This question focuses on seeking expert advice or practical tips for maintaining a healthy cat, which would provide insights into diet, grooming, exercise, and other essential aspects of pet care.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "prompt = \"\"\"Your goal is to generate targeted web search query.\n",
    "\n",
    "The query will gather information related to a specific topic.\n",
    "\n",
    "Topic: cats\n",
    "\n",
    "Return your query in the following JSON format:\n",
    "{{\n",
    "  \"query\": \"string\",\n",
    "  \"aspect\": \"string\",\n",
    "  \"rationale\": \"string\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "msg = llm_json.invoke(prompt)\n",
    "query = json.loads(msg.content)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to understand scaling laws for RL models. Hmm, where do I start? I remember from the previous summary that scaling laws are about how AI systems scale with data and compute. But let me try to break it down.\n",
      "\n",
      "First, there's linear scaling. That means if you give a model more data or computing power, its performance scales proportionally. So doubling the resources would double the performance. Makes sense because more data usually helps models learn better. I think this is common in many AI applications now, especially with big models like GPT-3.\n",
      "\n",
      "Then there's super-linear scaling. This happens when increasing resources leads to more than proportional gains. Maybe because the model can find more efficient ways to use the extra compute or data. For example, maybe adding more GPUs allows for better parallelization, so performance increases even more than expected. I wonder how that works in practice.\n",
      "\n",
      "Sub-linear scaling is trickier. Here, performance doesn't scale as well as resources. It could be because of communication overhead when using distributed systems. Like, if you have too many workers communicating with each other, it might slow things down. Or maybe the model's architecture isn't optimized for very large scales yet. I'm not entirely sure how this happens.\n",
      "\n",
      "Break-even scaling is about finding the point where adding more resources doesn't improve performance anymore. It's like hitting a limit where you've maxed out your system's capabilities, so increasing compute beyond that doesn't help. This must be important for optimizing costs in AI deployments.\n",
      "\n",
      "Phase transitions refer to sudden changes in model behavior as parameters change. I'm not too clear on this yet. Maybe it's when the model shifts from one type of performance to another, like moving from linear to sub-linear scaling suddenly at a certain resource level. It could relate to how models are designed and scaled.\n",
      "\n",
      "Power laws involve performance improving with the square root or cube root of resources. So adding more compute doesn't lead to linear gains but something less. I think this might happen when there's a physical limit, like memory constraints or network bandwidth that can't scale indefinitely.\n",
      "\n",
      "Efficiency scaling is about how well models use their resources. If efficiency improves, you get better performance per unit resource. This could be due to better algorithms or hardware utilization. It would help in making AI systems more cost-effective and scalable.\n",
      "\n",
      "As for applications, large language models definitely use these laws. They require lots of data and compute, so understanding scaling helps in planning resources. Autonomous systems might rely on them, so their reliability depends on how well the models scale with different inputs or environments.\n",
      "\n",
      "Computer vision uses a lot of data too, especially images and videos. Efficiently scaling vision models is crucial for real-time applications without high resource usage. Maybe techniques like model pruning help reduce compute needs while maintaining performance.\n",
      "\n",
      "AI safety is another area where these laws matter. If models don't scale safely, their behavior could become unpredictable at larger scales. Ensuring that scaling doesn't introduce unintended behaviors is vital for responsible AI development.\n",
      "\n",
      "Putting it all together, scaling laws are essential for optimizing AI systems across various domains. They help in planning resources efficiently and understanding the limits of model performance as they grow. I think I need to look into each of these categories more deeply to fully grasp how they apply in different contexts.\n",
      "</think>\n",
      "\n",
      "Scaling laws for AI models are crucial for understanding how their performance scales with data, compute, and other resources. Here's a structured summary:\n",
      "\n",
      "1. **Linear Scaling**: Performance increases proportionally with additional resources (data or compute). This is common in large models like GPT-3, where more resources lead to better learning outcomes.\n",
      "\n",
      "2. **Super-linear Scaling**: Performance gains exceed the proportional increase from added resources. This can occur due to efficient parallelization and optimization, allowing for enhanced performance as resources grow.\n",
      "\n",
      "3. **Sub-linear Scaling**: Performance increases less than proportionally with resource growth. Factors like communication overhead in distributed systems or architectural limitations can cause this inefficiency.\n",
      "\n",
      "4. **Break-even Scaling**: Beyond a certain point, adding more resources no longer improves performance. This is crucial for optimizing costs and avoiding unnecessary resource investment.\n",
      "\n",
      "5. **Phase Transitions**: Sudden changes in model behavior at specific resource levels, indicating shifts from one scaling regime to another, often due to architectural or design changes.\n",
      "\n",
      "6. **Power Laws**: Performance gains are proportional to a root function of resources (e.g., square root). This occurs when physical limits constrain scalability, such as memory or network constraints.\n",
      "\n",
      "7. **Efficiency Scaling**: Improvements in resource utilization enhance performance per unit resource, aiding cost-effectiveness and scalability through better algorithms or hardware use.\n",
      "\n",
      "**Applications**:\n",
      "- **Large Language Models**: Rely heavily on scaling laws to manage vast amounts of data and compute.\n",
      "- **Autonomous Systems**: Reliance on efficient scaling ensures reliability across diverse inputs and environments.\n",
      "- **Computer Vision**: Efficient scaling is vital for real-time applications, often achieved through techniques like model pruning.\n",
      "- **AI Safety**: Ensuring predictable behavior at larger scales is essential for responsible AI development.\n",
      "\n",
      "Understanding these laws helps optimize AI systems across domains, ensuring efficient resource planning and addressing potential scalability limits.\n"
     ]
    }
   ],
   "source": [
    "msg = llm.invoke(\"Give me a summary of scaling laws for RL models.\")\n",
    "print(msg.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
