{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzOv2nLVjK-8"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34zeS1w6XKf9",
        "outputId": "8dfee31c-3242-4150-ab65-036915c98898"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU gradio diffusers transformers accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbauyMMTjIl7"
      },
      "source": [
        "Instalowane są cztery biblioteki:\n",
        "- gradio - służy do tworzenia interfejsów graficznych dla modeli ML\n",
        "- diffusers - zawiera implementacje różnych modeli generatywnych\n",
        "- transformers - dostarcza modele językowe i narzędzia do ich obsługi\n",
        "- accelerate - optymalizuje działanie modeli na różnych typach procesorów\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnBcA3-NXCUY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import os\n",
        "# Scientific computing\n",
        "import numpy as np\n",
        "import torch\n",
        "# Machine learning\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "# UI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmDlYhPDjIl8"
      },
      "source": [
        "## Biblioteki\n",
        "* `numpy` - to fundament obliczeń numerycznych w Pythonie. W kontekście przetwarzania obrazów numpy jest niezbędny, ponieważ obrazy cyfrowe są reprezentowane jako wielowymiarowe tablice liczb.\n",
        "\n",
        "* `PyTorch` (torch) - to framework uczenia maszynowego, który będzie odpowiedzialny za wykonywanie obliczeń na naszych modelach generatywnych.\n",
        "\n",
        "* `diffusers` - `AutoencoderKL` to specjalny rodzaj sieci neuronowej, która potrafi kompresować i dekompresować obrazy, zachowując ich najważniejsze cechy. * `DiffusionPipeline` to ogólny interfejs do modeli generatywnych opartych na dyfuzji, a `StableDiffusionXLPipeline` to najnowsza, ulepszona wersja modelu Stable Diffusion, zaprojektowana do tworzenia obrazów o wysokiej jakości."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1ZcJvLA7xDPJ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p9otG88e2I_b"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "    device = 'cpu'\n",
        "    dtype = torch.float16\n",
        "    variant = \"fp16\"\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    CFG.device = \"mps\"\n",
        "if torch.cuda.is_available():\n",
        "    CFG.device = \"cuda\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4lMd81Mrzsg"
      },
      "source": [
        "\n",
        "\n",
        "`model` wskazuje na konkretną wersję modelu Stable Diffusion XL - jest to \"stabilityai/stable-diffusion-xl-base-1.0\", czyli bazowy model SDXL w wersji 1.0 stworzony przez Stability AI. Ten model jest znany z generowania obrazów w wysokiej rozdzielczości.\n",
        "\n",
        "`dtype` określa format danych jako torch.bfloat16 - jest to specjalny format liczb zmiennoprzecinkowych, który zapewnia dobry kompromis między precyzją obliczeń a zużyciem pamięci. Format bfloat16 wykorzystuje 16 bitów na liczbę, ale inaczej rozkłada bity między część całkowitą i ułamkową niż standardowy float16.\n",
        "\n",
        "Ostatni parametr `variant` ustawiony na \"fp16\" informuje, że model będzie działał w trybie połowicznej precyzji (16-bitowej). Jest to zgodne z wcześniejszym ustawieniem dtype i pozwala na szybsze obliczenia przy akceptowalnej utracie precyzji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyAwuLsTkRTM"
      },
      "source": [
        "# Funkcje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sjZoJf00kTYT"
      },
      "outputs": [],
      "source": [
        "def infer(prompt, seed = 42, width=1024, height=1024,\n",
        "          guidance_scale=5.0,  num_inference_steps= 5,\n",
        "          progress=gr.Progress(track_tqdm=True)):\n",
        "\n",
        "    generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "    image = pipe(\n",
        "        prompt = prompt, width = width, height = height,\n",
        "        num_inference_steps = num_inference_steps,\n",
        "        generator = generator, guidance_scale=guidance_scale\n",
        "    ).images[0]\n",
        "\n",
        "    return image, seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG29a73_r-IO"
      },
      "source": [
        "Ta funkcja `infer` odpowiada za proces generowania obrazu na podstawie opisu tekstowego. Przeanalizujmy jej działanie krok po kroku.\n",
        "\n",
        "Funkcja przyjmuje kilka parametrów wejściowych:\n",
        "- `prompt` to opis tekstowy obrazu, który chcemy wygenerować\n",
        "- `seed` (domyślnie 42) to ziarno losowości, które pozwala na odtworzenie dokładnie tego samego wyniku\n",
        "- `width` i `height` (domyślnie 1024x1024) określają rozmiar generowanego obrazu w pikselach\n",
        "- `guidance_scale` (domyślnie 5.0) kontroluje, jak bardzo model powinien trzymać się opisu tekstowego - wyższe wartości dają obrazy bardziej dosłownie odpowiadające promptowi\n",
        "- `num_inference_steps` (domyślnie 5) określa liczbę kroków procesu denoising, czyli usuwania szumu z obrazu\n",
        "- `progress` to pasek postępu z biblioteki gradio, który pokazuje stan generowania\n",
        "\n",
        "W pierwszym kroku funkcja tworzy generator liczb losowych (`torch.Generator()`), którego ziarno jest ustawiane na podstawie parametru `seed`. Dzięki temu możemy później wygenerować dokładnie ten sam obraz, podając to samo ziarno.\n",
        "\n",
        "Następnie wywoływany jest pipeline generacyjny (`pipe`), któremu przekazywane są wszystkie niezbędne parametry. Pipeline wykonuje właściwy proces generowania obrazu, który wewnętrznie polega na stopniowym usuwaniu szumu z losowo zainicjowanej macierzy pikseli, kierując się podanym opisem tekstowym.\n",
        "\n",
        "Metoda zwraca krotkę zawierającą dwa elementy:\n",
        "- **wygenerowany obraz** (pierwszy element z listy images zwróconej przez pipeline)\n",
        "- **użyte ziarno losowości** (seed)\n",
        "\n",
        "Ta implementacja pozwala na kontrolowane generowanie obrazów z możliwością powtórzenia dokładnie tego samego wyniku, co jest szczególnie przydatne przy debugowaniu i dopracowywaniu promptów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkMGkgEIkVhW"
      },
      "source": [
        "# Aplikacja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CADpIc_EXCUh",
        "outputId": "22da0353-d969-4479-ae97-f34bbed34ad4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  3.20steps/s]\n"
          ]
        }
      ],
      "source": [
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "      CFG.model,\n",
        "      torch_dtype= CFG.dtype,\n",
        "      variant = CFG.variant,\n",
        "      use_safetensors=True).to(CFG.device)\n",
        "\n",
        "\n",
        "MAX_SEED = np.iinfo(np.int32).max\n",
        "MAX_IMAGE_SIZE = 2048"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zvgwQx0sEVG"
      },
      "source": [
        "W dalszej części kodu definiowane są dwa ważne ograniczenia systemu:\n",
        "- `MAX_SEED` jest ustawiany na maksymalną wartość 32-bitowej liczby całkowitej (około 2.15 miliarda). Jest to górne ograniczenie dla ziarna losowości, które możemy użyć przy generowaniu obrazów.\n",
        "- `MAX_IMAGE_SIZE` wynosi 2048 pikseli i określa maksymalny rozmiar obrazu, jaki może zostać wygenerowany. To ograniczenie wynika z limitów pamięci i mocy obliczeniowej dostępnego sprzętu.\n",
        "\n",
        "Te stałe są istotne dla bezpiecznego działania systemu - zapobiegają próbom generowania zbyt dużych obrazów lub używania nieprawidłowych wartości ziarna losowości, co mogłoby prowadzić do błędów lub awarii systemu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692,
          "referenced_widgets": [
            "ca0021850ab343f99e1498128c658a2c",
            "f392f499df644fefae59ee8deaf28b12",
            "768b15710da2422d9af27446a3708c39",
            "c3a8ea1d1d0248d9b2e5858753473c71",
            "3ec43d24bad84c8b9a1cef0bf9344bbd",
            "6e698db8c09a4e10a651af297f0ab037",
            "d1e119c51a504588979304bfef565b62",
            "c4c743f458fc47f7b17b9664af2efc7d",
            "979c972e0b2c43b6988d5af01a7abcb8",
            "0dbab0f602f24db087a03d4eeded233f",
            "009aff99b688486f8927c3821dce5517"
          ]
        },
        "id": "GI_NoRfeXCUm",
        "outputId": "83298157-647b-4766-c678-58e927772635",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://9cbf4fb1d8823fbad0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://9cbf4fb1d8823fbad0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca0021850ab343f99e1498128c658a2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?steps/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9cbf4fb1d8823fbad0.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "\n",
        "    with gr.Column(elem_id=\"col-container\"):\n",
        "\n",
        "        with gr.Row():\n",
        "\n",
        "            prompt = gr.Text(\n",
        "                label=\"Prompt\", show_label=False,\n",
        "                max_lines=1, placeholder=\"Enter your prompt\",\n",
        "                container=False,\n",
        "            )\n",
        "            run_button = gr.Button(\"Run\", scale=0)\n",
        "\n",
        "        result = gr.Image(label=\"Result\", show_label=False)\n",
        "\n",
        "        with gr.Accordion(\"Advanced Settings\", open=False):\n",
        "\n",
        "            seed = gr.Slider(\n",
        "                label=\"Seed\", minimum=0,\n",
        "                maximum=MAX_SEED, step=1,\n",
        "                value=0, )\n",
        "\n",
        "            randomize_seed = gr.Checkbox(label=\"Randomize seed\", value=True)\n",
        "\n",
        "            with gr.Row():\n",
        "\n",
        "                width = gr.Slider(\n",
        "                    label=\"Width\", minimum=256, maximum=MAX_IMAGE_SIZE,\n",
        "                    step=32, value=512,\n",
        "                )\n",
        "\n",
        "                height = gr.Slider(\n",
        "                    label=\"Height\", minimum=256, maximum=MAX_IMAGE_SIZE,\n",
        "                    step=32, value=1024,\n",
        "                )\n",
        "\n",
        "            with gr.Row():\n",
        "\n",
        "                guidance_scale = gr.Slider(\n",
        "                    label=\"Guidance Scale\",\n",
        "                    minimum=1, maximum=15, step=0.1, value=3.5,\n",
        "                )\n",
        "\n",
        "                num_inference_steps = gr.Slider(\n",
        "                    label=\"Number of inference steps\",\n",
        "                    minimum=1, maximum=100, step=1, value= 5,\n",
        "                )\n",
        "\n",
        "\n",
        "    gr.on(\n",
        "        triggers=[run_button.click, prompt.submit],\n",
        "        fn = infer,\n",
        "        inputs = [prompt, seed, width, height,\n",
        "                  guidance_scale, num_inference_steps],\n",
        "        outputs = [result, seed]\n",
        "    )\n",
        "\n",
        "demo.launch(debug = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDPf3Zs5sW3b"
      },
      "source": [
        "`gr.Blocks()` zawiera całą strukturę interfejsu. Wewnątrz niego znajduje się kolumna (`gr.Column`), która organizuje wszystkie elementy pionowo.\n",
        "\n",
        "W górnej części interfejsu znajduje się rząd (`gr.Row`) zawierający dwa kluczowe elementy: pole tekstowe do wprowadzania promptu oraz przycisk \"Run\". Pole tekstowe jest skonfigurowane jako jednoliniowe, z placeholder tekstem \"Enter your prompt\", bez wyświetlanej etykiety, co zapewnia czysty i minimalistyczny wygląd.\n",
        "\n",
        "Pod tymi elementami znajduje się komponеnt wyświetlający wygenerowany obraz (`gr.Image`).\n",
        "\n",
        "Sekcja \"Advanced Settings\" jest ukryta w rozwijanym panelu (`gr.Accordion`). Zawiera ona szereg kontrolek pozwalających na precyzyjne dostrojenie procesu generowania:\n",
        "\n",
        "Pierwszy element to suwak do kontroli ziarna losowości (seed), który może przyjmować wartości od 0 do MAX_SEED. Obok niego znajduje się pole wyboru \"Randomize seed\", domyślnie zaznaczone, które pozwala na automatyczne losowanie ziarna.\n",
        "\n",
        "Następnie mamy dwa suwaki w jednym rzędzie, kontrolujące szerokość i wysokość generowanego obrazu. Oba pozwalają na wybór wartości od 256 do `MAX_IMAGE_SIZE` pikseli, z krokiem co 32 piksele.\n",
        "\n",
        "W ostatnim rzędzie znajdują się dwa istotne parametry:\n",
        "- Guidance Scale (skala naprowadzania) - kontroluje, jak ściśle model ma trzymać się promptu\n",
        "- Number of inference steps (liczba kroków wnioskowania) - określa, ile iteracji ma wykonać model podczas generowania obrazu\n",
        "\n",
        "Na końcu kod konfiguruje obsługę zdarzeń - zarówno kliknięcie przycisku \"Run\", jak i wciśnięcie Enter w polu promptu wywołuje funkcję `infer`. Funkcja ta otrzymuje wszystkie wartości z kontrolek jako parametry wejściowe i zwraca wygenerowany obraz oraz użyte ziarno losowości."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bw_RQ_jsoxH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30762,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "009aff99b688486f8927c3821dce5517": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dbab0f602f24db087a03d4eeded233f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ec43d24bad84c8b9a1cef0bf9344bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e698db8c09a4e10a651af297f0ab037": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768b15710da2422d9af27446a3708c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c743f458fc47f7b17b9664af2efc7d",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_979c972e0b2c43b6988d5af01a7abcb8",
            "value": 75
          }
        },
        "979c972e0b2c43b6988d5af01a7abcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3a8ea1d1d0248d9b2e5858753473c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dbab0f602f24db087a03d4eeded233f",
            "placeholder": "​",
            "style": "IPY_MODEL_009aff99b688486f8927c3821dce5517",
            "value": " 75/75 [00:31&lt;00:00,  2.42steps/s]"
          }
        },
        "c4c743f458fc47f7b17b9664af2efc7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0021850ab343f99e1498128c658a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f392f499df644fefae59ee8deaf28b12",
              "IPY_MODEL_768b15710da2422d9af27446a3708c39",
              "IPY_MODEL_c3a8ea1d1d0248d9b2e5858753473c71"
            ],
            "layout": "IPY_MODEL_3ec43d24bad84c8b9a1cef0bf9344bbd"
          }
        },
        "d1e119c51a504588979304bfef565b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f392f499df644fefae59ee8deaf28b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e698db8c09a4e10a651af297f0ab037",
            "placeholder": "​",
            "style": "IPY_MODEL_d1e119c51a504588979304bfef565b62",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
