{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwyBOOPeLh37"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "k5yT3UQvLVHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# !pip install -qU openai\n",
        "# from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "zzKr_FxPLVHl"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "X_pu8CG8N7OC"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    base_url = \"http://localhost:11434/v1\"\n",
        "    api_key = \"ollama\"  # required, but unused\n",
        "    model = \"gpt-4o-mini\"\n",
        "    num_tokens = 2000\n",
        "    temperature = 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybmtPls6OSGi"
      },
      "source": [
        "Ta czÄ™Å›Ä‡ kodu definiuje klasÄ™ konfiguracyjnÄ… `CFG`, ktÃ³ra sÅ‚uÅ¼y do przechowywania ustawieÅ„ modelu jÄ™zykowego. Jest to przykÅ‚ad zastosowania wzorca programistycznego znanego jako klasa konfiguracyjna - centralne miejsce do zarzÄ…dzania parametrami aplikacji.\n",
        "\n",
        "W tym konkretnym przypadku klasa zawiera tylko jednÄ… zmiennÄ… klasowÄ… `model`, ktÃ³rej przypisano wartoÅ›Ä‡ \"gpt-4o-mini\". Zmienna ta okreÅ›la, ktÃ³ry model OpenAI bÄ™dzie uÅ¼ywany do przetwarzania zapytaÅ„. Jest to szczegÃ³lnie istotne, poniewaÅ¼ rÃ³Å¼ne modele OpenAI majÄ… rÃ³Å¼ne moÅ¼liwoÅ›ci, koszty i limity.\n",
        "\n",
        "UÅ¼ywanie klasy konfiguracyjnej zamiast zwykÅ‚ej zmiennej ma kilka zalet. Po pierwsze, wszystkie ustawienia sÄ… zgrupowane w jednym miejscu, co uÅ‚atwia ich zarzÄ…dzanie i modyfikacjÄ™. Po drugie, taka struktura pozwala na Å‚atwe dodawanie kolejnych parametrÃ³w w przyszÅ‚oÅ›ci bez koniecznoÅ›ci modyfikacji pozostaÅ‚ych czÄ™Å›ci kodu. Po trzecie, klasa moÅ¼e byÄ‡ importowana i uÅ¼ywana w rÃ³Å¼nych miejscach projektu, co zapewnia spÃ³jnoÅ›Ä‡ konfiguracji w caÅ‚ej aplikacji.\n",
        "\n",
        "Jest to podobne do tablicy rozdzielczej w samochodzie - wszystkie waÅ¼ne wskaÅºniki i ustawienia sÄ… zgrupowane w jednym miejscu, dziÄ™ki czemu kierowca ma do nich Å‚atwy dostÄ™p i moÅ¼e szybko sprawdziÄ‡ lub zmieniÄ‡ potrzebne parametry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dRWiRWkLLVHn"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "def assert_env_key(key: str | None, name: str) -> None:\n",
        "    if not key:\n",
        "        raise ValueError(f\"{name} is not set, please update .env file\")\n",
        "    \n",
        "OPENAI_API_KEY_NAME = \"OPENAI_API_KEY\"\n",
        "OPENAI_API_KEY = os.getenv(OPENAI_API_KEY_NAME)\n",
        "# OPENAI_API_KEY = userdata.get(OPENAI_API_KEY_NAME) # Google colab env retrieval option\n",
        "assert_env_key(OPENAI_API_KEY, OPENAI_API_KEY_NAME)\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "# client = OpenAI(api_key = userdata.get('openaivision'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWglV5eNNBWK"
      },
      "source": [
        "# Eksperymant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tworzenie nowego asystenta w OpenAI API\n",
        "\n",
        "Ten kod tworzy asystenta w OpenAI API z okreÅ›lonymi ustawieniami:  \n",
        "\n",
        "---\n",
        "\n",
        "##### ðŸ”¹ **Metoda tworzenia:**\n",
        "- **`client.beta.assistants.create()`** â€“ UÅ¼ywana do utworzenia asystenta przez API w wersji beta.  \n",
        "\n",
        "---\n",
        "\n",
        "#### ðŸ”¹ **Parametry:**\n",
        "- **`name = \"helper2\"`** â€“ Nazwa asystenta to \"helper2\". UÅ‚atwia identyfikacjÄ™.  \n",
        "\n",
        "- **`instructions`** â€“ Wytyczne okreÅ›lajÄ…ce rolÄ™ i zachowanie asystenta jako **\"Business AI Guide\"**:  \n",
        "  - Upraszcza techniczne informacje na jÄ™zyk biznesowy  \n",
        "  - Unika Å¼argonu technicznego  \n",
        "  - Zachowuje formalny ton  \n",
        "  - Jest informacyjny i cierpliwy  \n",
        "  - Unika szczegÃ³Å‚Ã³w technicznych, chyba Å¼e wymagane  \n",
        "  - Nie angaÅ¼uje siÄ™ w dyskusje polityczne  \n",
        "  - Nie spekuluje  \n",
        "  - **Odpowiada \"I do not know\"**, gdy nie jest pewny odpowiedzi  \n",
        "  - Prosi o wyjaÅ›nienie **tylko raz na zapytanie**  \n",
        "\n",
        "- **`model = CFG.model`** â€“ OkreÅ›la model asystenta na podstawie konfiguracji w klasie `CFG`.  \n",
        "\n",
        "---\n",
        "\n",
        "#### ðŸ”¹ **Kontynuacja linii:**\n",
        "- **`\\`** na koÅ„cu linii pozwala na kontynuacjÄ™ dÅ‚ugiego tekstu w kolejnych liniach, poprawiajÄ…c czytelnoÅ›Ä‡ kodu.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ASBxYV09LVHo"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name = \"helper2\",\n",
        "    instructions = \"Your role as 'Business AI Guide' is to assist users with questions \\\n",
        "                    and explanations about Artificial Intelligence (AI) and \\\n",
        "                    Machine Learning (ML), tailored for business professionals. \\\n",
        "                    You should simplify complex technical information into clear,\\\n",
        "                    business-friendly language, avoiding technical jargon. \\\n",
        "                    Maintain a formal tone in your communications, being \\\n",
        "                    informative and patient, ensuring clarity for users\\\n",
        "                    without a technical background. Avoid detailed \\\n",
        "                    technical explanations unless specifically requested. \\\n",
        "                    Refrain from discussing politics or current affairs, \\\n",
        "                    and avoid speculating. If uncertain about an answer,\\\n",
        "                    respond with 'I do not know.' Limit yourself to asking \\\n",
        "                    for clarification only once per query; if the query \\\n",
        "                    remains unclear after that, provide the best answer \\\n",
        "                    you can, filling in any missing details as needed.\",\n",
        "     model = CFG.model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tworzenie nowego wÄ…tku konwersacji w OpenAI API\n",
        "\n",
        "Ten kod tworzy nowy wÄ…tek konwersacji i wyÅ›wietla jego szczegÃ³Å‚y:  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Tworzenie wÄ…tku:**\n",
        "- **`thread = client.beta.threads.create()`** â€“ Tworzy nowy wÄ…tek konwersacji.  \n",
        "  - **WÄ…tek** dziaÅ‚a jak kontener dla wymiany wiadomoÅ›ci miÄ™dzy uÅ¼ytkownikiem a asystentem.  \n",
        "  - Zapewnia **ciÄ…gÅ‚oÅ›Ä‡ i kontekst rozmowy**.  \n",
        "  - Po utworzeniu wÄ…tku API generuje unikalny identyfikator oraz inne metadane.  \n",
        "  - To jak zakÅ‚adanie nowego zeszytu â€“ kaÅ¼da wiadomoÅ›Ä‡ bÄ™dzie przypisana do tego samego wÄ…tku, co pozwala zachowaÄ‡ **spÃ³jnoÅ›Ä‡ konwersacji**.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **WyÅ›wietlanie szczegÃ³Å‚Ã³w:**\n",
        "- **`print(thread)`** â€“ WyÅ›wietla szczegÃ³Å‚y nowo utworzonego wÄ…tku:  \n",
        "  - Unikalny **identyfikator wÄ…tku**  \n",
        "  - **Czas utworzenia**  \n",
        "  - Inne **metadane** zwiÄ…zane z wÄ…tkiem  \n",
        "  - Pomaga to w **debugowaniu** oraz weryfikacji poprawnoÅ›ci utworzenia wÄ…tku.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Dlaczego to waÅ¼ne?**\n",
        "- Mechanizm wÄ…tkÃ³w umoÅ¼liwia prowadzenie **wielu rÃ³wnolegÅ‚ych konwersacji**, kaÅ¼dej z **wÅ‚asnym kontekstem i historiÄ…**.  \n",
        "- To jak prowadzenie kilku rozmÃ³w w osobnych pokojach â€“ kaÅ¼da ma **swÃ³j przebieg i kontekst**, nie mieszajÄ…c siÄ™ z innymi.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hNgJ-T3LVHp",
        "outputId": "979ee890-b099-4ea0-e802-f3f26fb1df1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thread(id='thread_u1zjmqIbjGfkVRDB1FY0MfYL', created_at=1739784403, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
          ]
        }
      ],
      "source": [
        "thread = client.beta.threads.create()\n",
        "print(thread)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWHGwAj8LVHq"
      },
      "source": [
        "## Tworzenie wiadomoÅ›ci w wÄ…tku konwersacji w OpenAI API\n",
        "\n",
        "Te linie kodu tworzÄ… nowÄ… wiadomoÅ›Ä‡ w utworzonym wczeÅ›niej wÄ…tku konwersacji, wykorzystujÄ…c API OpenAI:  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Metoda dodawania wiadomoÅ›ci:**\n",
        "- **`client.beta.threads.messages.create()`** â€“ Metoda, ktÃ³ra dodaje wiadomoÅ›Ä‡ do istniejÄ…cego wÄ…tku.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Parametry:**\n",
        "- **`thread_id = thread.id`** â€“ OkreÅ›la, do ktÃ³rego wÄ…tku ma zostaÄ‡ dodana wiadomoÅ›Ä‡. UÅ¼ywamy identyfikatora wÄ…tku z poprzedniego kroku. To jak wskazanie zeszytu, do ktÃ³rego chcemy dodaÄ‡ notatkÄ™.  \n",
        "\n",
        "- **`role = \"user\"`** â€“ OkreÅ›la, Å¼e wiadomoÅ›Ä‡ pochodzi od uÅ¼ytkownika. W OpenAI rozrÃ³Å¼nianie rÃ³l ma kluczowe znaczenie, poniewaÅ¼ wpÅ‚ywa na sposÃ³b interpretacji wiadomoÅ›ci przez asystenta. Rola dziaÅ‚a jak etykieta, ktÃ³ra mÃ³wi, kto wysÅ‚aÅ‚ wiadomoÅ›Ä‡.  \n",
        "\n",
        "- **`content = \"What is generative AI?\"`** â€“ TreÅ›Ä‡ wiadomoÅ›ci. W tym przypadku pytanie o sztucznÄ… inteligencjÄ™ generatywnÄ…, na ktÃ³re asystent udzieli odpowiedzi.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Jak to dziaÅ‚a?**\n",
        "System wiadomoÅ›ci dziaÅ‚a jak zapisywanie w zeszycie â€“ kaÅ¼da wiadomoÅ›Ä‡ to nowy wpis z informacjami o **roli** nadawcy i **treÅ›ci**.  \n",
        "Wszystkie wiadomoÅ›ci sÄ… poÅ‚Ä…czone poprzez identyfikator wÄ…tku, co pozwala asystentowi utrzymaÄ‡ **ciÄ…gÅ‚oÅ›Ä‡ rozmowy i kontekst**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Ch44Zlt9LVHq"
      },
      "outputs": [],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id = thread.id,\n",
        "    role = \"user\",\n",
        "    content = \"What is generative AI?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inicjowanie wykonania wÄ…tku konwersacji w OpenAI API\n",
        "\n",
        "Ten fragment kodu inicjuje wykonanie (run) wÄ…tku konwersacji, Å‚Ä…czÄ…c go z wczeÅ›niej utworzonym asystentem. To moment, w ktÃ³rym system zaczyna przetwarzaÄ‡ wiadomoÅ›Ä‡ i generowaÄ‡ odpowiedÅº.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Metoda inicjowania wÄ…tku:**\n",
        "- **`client.beta.threads.runs.create()`** â€“ Inicjuje wykonanie wÄ…tku konwersacji i Å‚Ä…czy go z asystentem.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Parametry:**\n",
        "- **`thread_id = thread.id`** â€“ OkreÅ›la, ktÃ³ry wÄ…tek konwersacji ma zostaÄ‡ \"uruchomiony\". To jak przekazanie zeszytu z pytaniem do nauczyciela â€“ musimy wskazaÄ‡, ktÃ³rÄ… rozmowÄ™ asystent ma przeanalizowaÄ‡ i na co odpowiedzieÄ‡.  \n",
        "\n",
        "- **`assistant_id = assistant.id`** â€“ OkreÅ›la, ktÃ³ry asystent ma zajÄ…Ä‡ siÄ™ tym wÄ…tkiem. ÅÄ…czymy wÄ…tek z asystentem, ktÃ³ry posiada odpowiednie instrukcje i specjalizacjÄ™ (np. asystent biznesowy).  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Jak to dziaÅ‚a?**\n",
        "- **System OpenAI** analizuje historiÄ™ wÄ…tku, bierze pod uwagÄ™ instrukcje asystenta i rozpoczyna proces generowania odpowiedzi.  \n",
        "- To jak moment, gdy nauczyciel czyta pytanie ucznia i zastanawia siÄ™ nad odpowiedziÄ…, uwzglÄ™dniajÄ…c wczeÅ›niejszÄ… dyskusjÄ™ i swoje wytyczne.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **WaÅ¼na uwaga:**\n",
        "- Utworzenie \"run\" nie oznacza natychmiastowej odpowiedzi â€“ to **inicjowanie procesu** jej tworzenia.  \n",
        "- To jak przekazanie pytania nauczycielowi â€“ odpowiedÅº nadejdzie, ale potrzebny jest czas na jej przygotowanie.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8Huk8JwcLVHr"
      },
      "outputs": [],
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "    thread_id = thread.id,\n",
        "    assistant_id= assistant.id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PÄ™tla oczekiwania na odpowiedÅº od asystenta w OpenAI API\n",
        "\n",
        "Ta pÄ™tla **`while True`** implementuje mechanizm oczekiwania i pobierania odpowiedzi od asystenta. Oto jak dziaÅ‚a krok po kroku:\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Sprawdzanie statusu wÄ…tku:**\n",
        "- **`client.beta.threads.runs.retrieve()`** â€“ Sprawdza status wykonania wÄ…tku, uÅ¼ywajÄ…c identyfikatorÃ³w wÄ…tku (`thread_id`) i wykonania (`run_id`).  \n",
        "  - To jak zaglÄ…danie nauczycielowi przez ramiÄ™, aby sprawdziÄ‡, czy odpowiedÅº jest gotowa.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Przerwa miÄ™dzy sprawdzeniami:**\n",
        "- **`time.sleep(10)`** â€“ Wprowadza 10-sekundowÄ… przerwÄ™ miÄ™dzy kolejnymi zapytaniami do API.  \n",
        "  - WaÅ¼ne, aby nie przeciÄ…Å¼aÄ‡ API zbyt czÄ™stymi zapytaniami i daÄ‡ systemowi czas na przetworzenie odpowiedzi.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Sprawdzanie zakoÅ„czenia procesu:**\n",
        "- **`if run_status.status == 'completed'`** â€“ Sprawdza, czy asystent zakoÅ„czyÅ‚ juÅ¼ pracÄ™ nad odpowiedziÄ….  \n",
        "  - **`messages = client.beta.threads.messages.list(thread_id=thread.id)`** â€“ Pobiera historiÄ™ wiadomoÅ›ci z wÄ…tku, w tym odpowiedÅº asystenta.  \n",
        "  - **`break`** â€“ KoÅ„czy pÄ™tlÄ™, gdy odpowiedÅº jest gotowa.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Dodatkowe opÃ³Åºnienie:**\n",
        "- **`else` z `time.sleep(2)`** â€“ JeÅ›li odpowiedÅº nie jest jeszcze gotowa, dodaje 2-sekundowÄ… przerwÄ™.  \n",
        "  - Pomaga to w zarzÄ…dzaniu zasobami i ogranicza czÄ™stotliwoÅ›Ä‡ zapytaÅ„.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **Jak to dziaÅ‚a?**\n",
        "CaÅ‚y ten mechanizm przypomina czekanie na odpowiedÅº od eksperta: regularnie sprawdzamy, czy skoÅ„czyÅ‚, ale robimy to w rozsÄ…dnych odstÄ™pach czasu, nie zaglÄ…dajÄ…c co sekundÄ™. Gdy odpowiedÅº jest gotowa, moÅ¼emy jÄ… odczytaÄ‡ i przetwarzaÄ‡.  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ **PrzydatnoÅ›Ä‡:**\n",
        "- Tego typu mechanizm jest szczegÃ³lnie uÅ¼yteczny w **systemach asynchronicznych**, gdzie czas generowania odpowiedzi moÅ¼e byÄ‡ zmienny, zaleÅ¼ny od zÅ‚oÅ¼onoÅ›ci pytania i obciÄ…Å¼enia systemu.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BDKppaXRLVHs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error details (if available): You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "No active exception to reraise",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[37], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m run_status\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError details (if available): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_status\u001b[38;5;241m.\u001b[39mlast_error\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    run_status = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\n",
        "    if run_status.status == 'completed':\n",
        "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "        break\n",
        "    elif run_status.status == 'failed':\n",
        "        print(f\"Error details (if available): {run_status.last_error.message}\")\n",
        "        raise\n",
        "    else:\n",
        "        time.sleep(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7N8hID0LVHt",
        "outputId": "e1c2d96e-e9e9-4f2b-e3c3-08dd7adb01c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user:What is generative AI?\n"
          ]
        }
      ],
      "source": [
        "for message in reversed(messages.data):\n",
        "    print(message.role + \":\" + message.content[0].text.value)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 5601552,
          "sourceId": 9258072,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
