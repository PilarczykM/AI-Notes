{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwyBOOPeLh37"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "k5yT3UQvLVHb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# !pip install -qU openai python-dotenv\n",
        "# from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zzKr_FxPLVHl"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X_pu8CG8N7OC"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    model = \"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRWiRWkLLVHn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "def assert_env_key(key: str | None, name: str) -> None:\n",
        "    if not key:\n",
        "        raise ValueError(f\"{name} is not set, please update .env file\")\n",
        "    \n",
        "OPENAI_API_KEY_NAME = \"OPENAI_API_KEY\"\n",
        "OPENAI_API_KEY = os.getenv(OPENAI_API_KEY_NAME)\n",
        "# OPENAI_API_KEY = userdata.get(OPENAI_API_KEY_NAME) # Google colab env retrieval option\n",
        "assert_env_key(OPENAI_API_KEY, OPENAI_API_KEY_NAME)\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWglV5eNNBWK"
      },
      "source": [
        "# Eksperyment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tworzenie nowego asystenta w OpenAI API\n",
        "\n",
        "[Link](https://platform.openai.com/docs/assistants/overview)\n",
        "\n",
        "Ten kod tworzy asystenta w OpenAI API z okreÅ›lonymi ustawieniami:  \n",
        "\n",
        "---\n",
        "\n",
        "##### ğŸ”¹ **Metoda tworzenia:**\n",
        "- **`client.beta.assistants.create()`** â€“ UÅ¼ywana do utworzenia asystenta przez API w wersji beta.  \n",
        "\n",
        "---\n",
        "\n",
        "#### ğŸ”¹ **Parametry:**\n",
        "- **`name = \"helper2\"`** â€“ Nazwa asystenta to \"helper2\". UÅ‚atwia identyfikacjÄ™.  \n",
        "\n",
        "- **`instructions`** â€“ Wytyczne okreÅ›lajÄ…ce rolÄ™ i zachowanie asystenta jako **\"Business AI Guide\"**:  \n",
        "  - Upraszcza techniczne informacje na jÄ™zyk biznesowy  \n",
        "  - Unika Å¼argonu technicznego  \n",
        "  - Zachowuje formalny ton  \n",
        "  - Jest informacyjny i cierpliwy  \n",
        "  - Unika szczegÃ³Å‚Ã³w technicznych, chyba Å¼e wymagane  \n",
        "  - Nie angaÅ¼uje siÄ™ w dyskusje polityczne  \n",
        "  - Nie spekuluje  \n",
        "  - **Odpowiada \"I do not know\"**, gdy nie jest pewny odpowiedzi  \n",
        "  - Prosi o wyjaÅ›nienie **tylko raz na zapytanie**  \n",
        "\n",
        "- **`model = CFG.model`** â€“ OkreÅ›la model asystenta na podstawie konfiguracji w klasie `CFG`.  \n",
        "\n",
        "---\n",
        "\n",
        "#### ğŸ”¹ **Kontynuacja linii:**\n",
        "- **`\\`** na koÅ„cu linii pozwala na kontynuacjÄ™ dÅ‚ugiego tekstu w kolejnych liniach, poprawiajÄ…c czytelnoÅ›Ä‡ kodu.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASBxYV09LVHo"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name = \"helper2\",\n",
        "    instructions = \"Your role as 'Business AI Guide' is to assist users with questions \\\n",
        "                    and explanations about Artificial Intelligence (AI) and \\\n",
        "                    Machine Learning (ML), tailored for business professionals. \\\n",
        "                    You should simplify complex technical information into clear,\\\n",
        "                    business-friendly language, avoiding technical jargon. \\\n",
        "                    Maintain a formal tone in your communications, being \\\n",
        "                    informative and patient, ensuring clarity for users\\\n",
        "                    without a technical background. Avoid detailed \\\n",
        "                    technical explanations unless specifically requested. \\\n",
        "                    Refrain from discussing politics or current affairs, \\\n",
        "                    and avoid speculating. If uncertain about an answer,\\\n",
        "                    respond with 'I do not know.' Limit yourself to asking \\\n",
        "                    for clarification only once per query; if the query \\\n",
        "                    remains unclear after that, provide the best answer \\\n",
        "                    you can, filling in any missing details as needed.\",\n",
        "     model = CFG.model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-27T23:34:18.464885Z",
          "iopub.status.busy": "2024-08-27T23:34:18.464490Z",
          "iopub.status.idle": "2024-08-27T23:34:18.484597Z",
          "shell.execute_reply": "2024-08-27T23:34:18.483212Z",
          "shell.execute_reply.started": "2024-08-27T23:34:18.464847Z"
        },
        "id": "3EzPG9bJLVHo"
      },
      "source": [
        "## Tworzenie nowego wÄ…tku konwersacji w OpenAI API\n",
        "\n",
        "Ten kod tworzy nowy wÄ…tek konwersacji i wyÅ›wietla jego szczegÃ³Å‚y:  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Tworzenie wÄ…tku:**\n",
        "- **`thread = client.beta.threads.create()`** â€“ Tworzy nowy wÄ…tek konwersacji.  \n",
        "  - **WÄ…tek** dziaÅ‚a jak kontener dla wymiany wiadomoÅ›ci miÄ™dzy uÅ¼ytkownikiem a asystentem.  \n",
        "  - Zapewnia **ciÄ…gÅ‚oÅ›Ä‡ i kontekst rozmowy**.  \n",
        "  - Po utworzeniu wÄ…tku API generuje unikalny identyfikator oraz inne metadane.  \n",
        "  - To jak zakÅ‚adanie nowego zeszytu â€“ kaÅ¼da wiadomoÅ›Ä‡ bÄ™dzie przypisana do tego samego wÄ…tku, co pozwala zachowaÄ‡ **spÃ³jnoÅ›Ä‡ konwersacji**.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **WyÅ›wietlanie szczegÃ³Å‚Ã³w:**\n",
        "- **`print(thread)`** â€“ WyÅ›wietla szczegÃ³Å‚y nowo utworzonego wÄ…tku:  \n",
        "  - Unikalny **identyfikator wÄ…tku**  \n",
        "  - **Czas utworzenia**  \n",
        "  - Inne **metadane** zwiÄ…zane z wÄ…tkiem  \n",
        "  - Pomaga to w **debugowaniu** oraz weryfikacji poprawnoÅ›ci utworzenia wÄ…tku.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Dlaczego to waÅ¼ne?**\n",
        "- Mechanizm wÄ…tkÃ³w umoÅ¼liwia prowadzenie **wielu rÃ³wnolegÅ‚ych konwersacji**, kaÅ¼dej z **wÅ‚asnym kontekstem i historiÄ…**.  \n",
        "- To jak prowadzenie kilku rozmÃ³w w osobnych pokojach â€“ kaÅ¼da ma **swÃ³j przebieg i kontekst**, nie mieszajÄ…c siÄ™ z innymi.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hNgJ-T3LVHp",
        "outputId": "979ee890-b099-4ea0-e802-f3f26fb1df1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thread(id='thread_ABKB88Bnax3Mmsj84TJdSxpG', created_at=1736547906, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
          ]
        }
      ],
      "source": [
        "thread = client.beta.threads.create()\n",
        "print(thread)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfhgFk7DLVHp"
      },
      "source": [
        "## Tworzenie wiadomoÅ›ci w wÄ…tku konwersacji w OpenAI API\n",
        "\n",
        "Te linie kodu tworzÄ… nowÄ… wiadomoÅ›Ä‡ w utworzonym wczeÅ›niej wÄ…tku konwersacji, wykorzystujÄ…c API OpenAI:  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Metoda dodawania wiadomoÅ›ci:**\n",
        "- **`client.beta.threads.messages.create()`** â€“ Metoda, ktÃ³ra dodaje wiadomoÅ›Ä‡ do istniejÄ…cego wÄ…tku.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Parametry:**\n",
        "- **`thread_id = thread.id`** â€“ OkreÅ›la, do ktÃ³rego wÄ…tku ma zostaÄ‡ dodana wiadomoÅ›Ä‡. UÅ¼ywamy identyfikatora wÄ…tku z poprzedniego kroku. To jak wskazanie zeszytu, do ktÃ³rego chcemy dodaÄ‡ notatkÄ™.  \n",
        "\n",
        "- **`role = \"user\"`** â€“ OkreÅ›la, Å¼e wiadomoÅ›Ä‡ pochodzi od uÅ¼ytkownika. W OpenAI rozrÃ³Å¼nianie rÃ³l ma kluczowe znaczenie, poniewaÅ¼ wpÅ‚ywa na sposÃ³b interpretacji wiadomoÅ›ci przez asystenta. Rola dziaÅ‚a jak etykieta, ktÃ³ra mÃ³wi, kto wysÅ‚aÅ‚ wiadomoÅ›Ä‡.  \n",
        "\n",
        "- **`content = \"What is generative AI?\"`** â€“ TreÅ›Ä‡ wiadomoÅ›ci. W tym przypadku pytanie o sztucznÄ… inteligencjÄ™ generatywnÄ…, na ktÃ³re asystent udzieli odpowiedzi.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Jak to dziaÅ‚a?**\n",
        "System wiadomoÅ›ci dziaÅ‚a jak zapisywanie w zeszycie â€“ kaÅ¼da wiadomoÅ›Ä‡ to nowy wpis z informacjami o **roli** nadawcy i **treÅ›ci**.  \n",
        "Wszystkie wiadomoÅ›ci sÄ… poÅ‚Ä…czone poprzez identyfikator wÄ…tku, co pozwala asystentowi utrzymaÄ‡ **ciÄ…gÅ‚oÅ›Ä‡ rozmowy i kontekst**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch44Zlt9LVHq"
      },
      "outputs": [],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id = thread.id,\n",
        "    role = \"user\",\n",
        "    content = \"What is generative AI?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9n3EIN6LVHr"
      },
      "source": [
        "## Inicjowanie wykonania wÄ…tku konwersacji w OpenAI API\n",
        "\n",
        "Ten fragment kodu inicjuje wykonanie (run) wÄ…tku konwersacji, Å‚Ä…czÄ…c go z wczeÅ›niej utworzonym asystentem. To moment, w ktÃ³rym system zaczyna przetwarzaÄ‡ wiadomoÅ›Ä‡ i generowaÄ‡ odpowiedÅº.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Metoda inicjowania wÄ…tku:**\n",
        "- **`client.beta.threads.runs.create()`** â€“ Inicjuje wykonanie wÄ…tku konwersacji i Å‚Ä…czy go z asystentem.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Parametry:**\n",
        "- **`thread_id = thread.id`** â€“ OkreÅ›la, ktÃ³ry wÄ…tek konwersacji ma zostaÄ‡ \"uruchomiony\". To jak przekazanie zeszytu z pytaniem do nauczyciela â€“ musimy wskazaÄ‡, ktÃ³rÄ… rozmowÄ™ asystent ma przeanalizowaÄ‡ i na co odpowiedzieÄ‡.  \n",
        "\n",
        "- **`assistant_id = assistant.id`** â€“ OkreÅ›la, ktÃ³ry asystent ma zajÄ…Ä‡ siÄ™ tym wÄ…tkiem. ÅÄ…czymy wÄ…tek z asystentem, ktÃ³ry posiada odpowiednie instrukcje i specjalizacjÄ™ (np. asystent biznesowy).  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Jak to dziaÅ‚a?**\n",
        "- **System OpenAI** analizuje historiÄ™ wÄ…tku, bierze pod uwagÄ™ instrukcje asystenta i rozpoczyna proces generowania odpowiedzi.  \n",
        "- To jak moment, gdy nauczyciel czyta pytanie ucznia i zastanawia siÄ™ nad odpowiedziÄ…, uwzglÄ™dniajÄ…c wczeÅ›niejszÄ… dyskusjÄ™ i swoje wytyczne.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **WaÅ¼na uwaga:**\n",
        "- Utworzenie \"run\" nie oznacza natychmiastowej odpowiedzi â€“ to **inicjowanie procesu** jej tworzenia.  \n",
        "- To jak przekazanie pytania nauczycielowi â€“ odpowiedÅº nadejdzie, ale potrzebny jest czas na jej przygotowanie.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Huk8JwcLVHr"
      },
      "outputs": [],
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "    thread_id = thread.id,\n",
        "    assistant_id= assistant.id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PÄ™tla oczekiwania na odpowiedÅº od asystenta w OpenAI API\n",
        "\n",
        "Ta pÄ™tla **`while True`** implementuje mechanizm oczekiwania i pobierania odpowiedzi od asystenta. Oto jak dziaÅ‚a krok po kroku:\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Sprawdzanie statusu wÄ…tku:**\n",
        "- **`client.beta.threads.runs.retrieve()`** â€“ Sprawdza status wykonania wÄ…tku, uÅ¼ywajÄ…c identyfikatorÃ³w wÄ…tku (`thread_id`) i wykonania (`run_id`).  \n",
        "  - To jak zaglÄ…danie nauczycielowi przez ramiÄ™, aby sprawdziÄ‡, czy odpowiedÅº jest gotowa.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Przerwa miÄ™dzy sprawdzeniami:**\n",
        "- **`time.sleep(10)`** â€“ Wprowadza 10-sekundowÄ… przerwÄ™ miÄ™dzy kolejnymi zapytaniami do API.  \n",
        "  - WaÅ¼ne, aby nie przeciÄ…Å¼aÄ‡ API zbyt czÄ™stymi zapytaniami i daÄ‡ systemowi czas na przetworzenie odpowiedzi.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Sprawdzanie zakoÅ„czenia procesu:**\n",
        "- **`if run_status.status == 'completed'`** â€“ Sprawdza, czy asystent zakoÅ„czyÅ‚ juÅ¼ pracÄ™ nad odpowiedziÄ….  \n",
        "  - **`messages = client.beta.threads.messages.list(thread_id=thread.id)`** â€“ Pobiera historiÄ™ wiadomoÅ›ci z wÄ…tku, w tym odpowiedÅº asystenta.  \n",
        "  - **`break`** â€“ KoÅ„czy pÄ™tlÄ™, gdy odpowiedÅº jest gotowa.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Dodatkowe opÃ³Åºnienie:**\n",
        "- **`else` z `time.sleep(2)`** â€“ JeÅ›li odpowiedÅº nie jest jeszcze gotowa, dodaje 2-sekundowÄ… przerwÄ™.  \n",
        "  - Pomaga to w zarzÄ…dzaniu zasobami i ogranicza czÄ™stotliwoÅ›Ä‡ zapytaÅ„.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **Jak to dziaÅ‚a?**\n",
        "CaÅ‚y ten mechanizm przypomina czekanie na odpowiedÅº od eksperta: regularnie sprawdzamy, czy skoÅ„czyÅ‚, ale robimy to w rozsÄ…dnych odstÄ™pach czasu, nie zaglÄ…dajÄ…c co sekundÄ™. Gdy odpowiedÅº jest gotowa, moÅ¼emy jÄ… odczytaÄ‡ i przetwarzaÄ‡.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ **PrzydatnoÅ›Ä‡:**\n",
        "- Tego typu mechanizm jest szczegÃ³lnie uÅ¼yteczny w **systemach asynchronicznych**, gdzie czas generowania odpowiedzi moÅ¼e byÄ‡ zmienny, zaleÅ¼ny od zÅ‚oÅ¼onoÅ›ci pytania i obciÄ…Å¼enia systemu.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BDKppaXRLVHs"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    run_status = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\n",
        "    time.sleep(10)\n",
        "    if run_status.status == 'completed':\n",
        "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "        break\n",
        "    else:\n",
        "        time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7N8hID0LVHt",
        "outputId": "e1c2d96e-e9e9-4f2b-e3c3-08dd7adb01c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user:What is generative AI?\n",
            "assistant:Generative AI is a type of artificial intelligence that can create new content, such as text, images, music, or even videos, based on the patterns it has learned from existing data. Unlike traditional AI, which may simply analyze or classify data, generative AI goes a step further by generating original outputs that mimic the style or characteristics of the input it has been trained on.\n",
            "\n",
            "In business, generative AI can be utilized for a variety of applications, including content creation for marketing, designing products, enhancing customer service with chatbots, and more. It essentially leverages large datasets to produce creative and innovative solutions, which can help companies save time and improve efficiency.\n"
          ]
        }
      ],
      "source": [
        "for message in reversed(messages.data):\n",
        "    print(message.role + \":\" + message.content[0].text.value)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 5601552,
          "sourceId": 9258072,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
