{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The guessing Game\n",
    "\n",
    "Concept of this game is quite easy. Two models interact with each other to guess noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST_TEMPLATE = \"\"\"\n",
    "You are the host of a game where a player asks questions about\n",
    "a thing to guess what it is.\n",
    "\n",
    "Write the name of a thing. It must be a common object.\n",
    "It must be a single word. Do not write anything else. \n",
    "Only write the name of the thing with no punctuation.\n",
    "\n",
    "Here is a list of things you cannot use:\n",
    "{history}\n",
    "\"\"\"\n",
    "\n",
    "QUESTION_TEMPLATE = \"\"\"\n",
    "You are a player in a game where you need to ask Yes/No questions about \n",
    "a thing and guess what it is.\n",
    "\n",
    "The thing is a common object. It is a single word.\n",
    "\n",
    "Here are the questions you have already asked:\n",
    "\n",
    "{observations}\n",
    "\n",
    "You only have {questions_left} questions left to ask. You want to guess\n",
    "in as few questions as possible.\n",
    "If there's only 1 question left, \n",
    "you must make a guess or you'll lose the game. Be aggressive and try to\n",
    "guess the thing as soon as possible.\n",
    "\n",
    "Do not ask questions that you have already asked before.\n",
    "\n",
    "Only binary question are allowed. The question must be answered\n",
    "with a Yes/No.\n",
    "\n",
    "Be as concise as possible when asking a question. Do not announce that you\n",
    "will ask the question. Do not say \"Let's get started\", or introduce your \n",
    "question. Just write the question.\n",
    "\n",
    "Examples of good questions:\n",
    "\n",
    "- Is it a fruit?\n",
    "- Is it bigger than a car?\n",
    "- Is it alive?\n",
    "\n",
    "Examples of bad questions:\n",
    "\n",
    "- Can I ask a question?\n",
    "- Can you tell me more about the thing?\n",
    "- What is the thing?\n",
    "- How does the thing look like?\n",
    "\"\"\"\n",
    "\n",
    "ANSWER_TEMPLATE = \"\"\"\n",
    "You are the host of a game where a player asks questions about\n",
    "a {concept} trying to guess what it is.\n",
    "\n",
    "The player has asked you the following question: {question}.\n",
    "\n",
    "If the player guessed that the thing is \"{concept}\" doesn't mather if written lover case or upper case, answer with the word \"GUESSED\".\n",
    "If the question refers specific to \"{concept}\", answer with the word \"GUESSED\".\n",
    "\n",
    "If the player didn't guessed, answer the question with a \n",
    "simple Yes or No. Do not say anything else. Do not use any punctuation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper to initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from httpx import ConnectError\n",
    "from langchain_core.language_models.llms import BaseLLM\n",
    "from langchain_ollama import OllamaLLM\n",
    "from ollama import ResponseError\n",
    "\n",
    "\n",
    "def create_model(model_name: str = \"llama3.2\") -> BaseLLM:\n",
    "    model = OllamaLLM(model=model_name)\n",
    "    try:\n",
    "        print(model.invoke(\"Say hello\"))\n",
    "    except ResponseError as e:\n",
    "        print(\"Ollama model not found. Pull it or change.\")\n",
    "        print(e)\n",
    "        exit(1)\n",
    "    except ConnectError as e:\n",
    "        print(\"Ollama application is not running. Starting it or download.\")\n",
    "        print(e)\n",
    "        exit(1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Class\n",
    "\n",
    "Player represents model with:\n",
    "* ability to initialize game with concept\n",
    "* ask question with some kind of history\n",
    "* answer question based on output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models.llms import BaseLLM\n",
    "from langchain_core.prompts.base import BasePromptTemplate\n",
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "\n",
    "\n",
    "class Player:\n",
    "    def __init__(self, model: BaseLLM):\n",
    "        self.observations = []\n",
    "        self.model = model\n",
    "        self.concept = None\n",
    "        self.history = []\n",
    "\n",
    "    def initialize_host(self, prompt_template: BasePromptTemplate, output_parser: BaseOutputParser):\n",
    "        prompt = prompt_template.from_template(HOST_TEMPLATE)\n",
    "        chain = prompt | self.model | output_parser\n",
    "\n",
    "        self.concept = chain.invoke({\"history\": self.history})\n",
    "        self.history.append(self.concept)\n",
    "\n",
    "        print(f\"Concept: {self.concept}\")\n",
    "\n",
    "    def initialize_player(self):\n",
    "        self.observations = []\n",
    "\n",
    "    def ask_question(\n",
    "        self, prompt_template: BasePromptTemplate, output_parser, questions_left\n",
    "    ):\n",
    "        prompt = prompt_template.from_template(QUESTION_TEMPLATE)\n",
    "        chain = prompt | self.model | output_parser\n",
    "\n",
    "        question = chain.invoke(\n",
    "            {\n",
    "                \"observations\": \"\\n\".join(self.observations),\n",
    "                \"questions_left\": questions_left,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.observations.append(question)\n",
    "\n",
    "        return question\n",
    "\n",
    "    def answer_question(\n",
    "        self, prompt_template: BasePromptTemplate, output_parser, question\n",
    "    ):\n",
    "        prompt = prompt_template.from_template(ANSWER_TEMPLATE)\n",
    "        chain = prompt | self.model | output_parser\n",
    "\n",
    "        return chain.invoke({\"concept\": self.concept, \"question\": question})\n",
    "\n",
    "    def add_observation(self, question: str, answer: str):\n",
    "        self.observations.append(f\"Question: {question}. Answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing player object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "player = Player(model=model)\n",
    "player.initialize_host(prompt_template=PromptTemplate, output_parser=StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = player.ask_question(prompt_template=PromptTemplate, output_parser=StrOutputParser(), questions_left=20)\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player.answer_question(prompt_template=PromptTemplate, output_parser=StrOutputParser(), question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models.llms import BaseLLM\n",
    "from langchain_core.prompts.base import BasePromptTemplate\n",
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model1: BaseLLM,\n",
    "        model2: BaseLLM,\n",
    "        prompt_template: BasePromptTemplate,\n",
    "        output_parser: BaseOutputParser,\n",
    "        rounds: int = 3,\n",
    "        questions: int = 20,\n",
    "    ):\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.prompt_template = prompt_template\n",
    "        self.output_parser = output_parser\n",
    "        self.rounds = rounds\n",
    "        self.questions = questions\n",
    "\n",
    "    def start(self):\n",
    "        players = {\n",
    "            \"0\": {\n",
    "                \"player\": Player(self.model1),\n",
    "                \"score\": 0,\n",
    "            },\n",
    "            \"1\": {\n",
    "                \"player\": Player(self.model2),\n",
    "                \"score\": 0,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        host_index = 0\n",
    "        for round in range(self.rounds):\n",
    "            print(f\"Round {round + 1}. Player {host_index + 1} is the host.\")\n",
    "\n",
    "            player_index = 1 - host_index\n",
    "            if self._play(\n",
    "                players[str(host_index)][\"player\"], players[str(player_index)][\"player\"]\n",
    "            ):\n",
    "                print(f\"Player {player_index + 1} guessed correctly.\")\n",
    "                players[str(player_index)][\"score\"] += 1\n",
    "            else:\n",
    "                print(f\"Player {player_index + 1} didn't guess correctly.\")\n",
    "                players[str(host_index)][\"score\"] += 1\n",
    "\n",
    "            host_index = 1 - host_index\n",
    "\n",
    "        print(\"Final score:\")\n",
    "        print(f\"Player 1: {players['0']['score']}\")\n",
    "        print(f\"Player 2: {players['1']['score']}\")\n",
    "\n",
    "    def _play(self, host: Player, player: Player):\n",
    "        host.initialize_host(self.prompt_template, self.output_parser)\n",
    "        player.initialize_player()\n",
    "        for question_index in range(self.questions):\n",
    "            question = player.ask_question(\n",
    "                self.prompt_template,\n",
    "                self.output_parser,\n",
    "                self.questions - question_index,\n",
    "            )\n",
    "            answer = host.answer_question(\n",
    "                self.prompt_template, self.output_parser, question\n",
    "            )\n",
    "\n",
    "            print(f\"Question {question_index + 1}: {question}. Answer: {answer}\")\n",
    "\n",
    "            player.add_observation(question, answer)\n",
    "\n",
    "            if \"guessed\" in answer.lower():\n",
    "                return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game starts here\n",
    "\n",
    "> Remember to run all previous steps to correctly run game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "game = Game(\n",
    "    model1=create_model(model_name=\"llama3.2\"),\n",
    "    model2=create_model(model_name=\"llama3.2\"),\n",
    "    rounds=7,\n",
    "    prompt_template=PromptTemplate,\n",
    "    output_parser=StrOutputParser(),\n",
    ")\n",
    "\n",
    "game.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
