# Embedding Models and Their Purpose

Embedding models are machine learning models that transform high-dimensional data (such as text, images, or graphs) into dense vector representations. These embeddings capture semantic relationships and are useful for various tasks like search, recommendation systems, and NLP.

## **📌 Categories of Embedding Models**

### **1️⃣ Text Embeddings**
Used for NLP tasks like semantic search, text classification, and similarity matching.  
- **Word2Vec** (Google) – Learns word embeddings to capture semantic similarities.  
- **GloVe** (Stanford) – Generates word vectors using co-occurrence statistics.  
- **FastText** (Facebook) – Enhances Word2Vec by considering subword information.  
- **BERT Embeddings** (Google) – Context-aware embeddings for NLP tasks.  
- **GPT-based Embeddings** (OpenAI) – Sentence and document-level embeddings.  
- **Universal Sentence Encoder (USE)** (Google) – Optimized for semantic similarity.  
- **Nomic-Embed-Text** – A modern text embedding model useful for retrieval and clustering.  

### **2️⃣ Image Embeddings**
Used for image classification, retrieval, and feature extraction.  
- **ResNet Embeddings** (Microsoft) – Extracts feature vectors from images.  
- **VGG Embeddings** (Oxford) – Deep image features for recognition.  
- **CLIP Embeddings** (OpenAI) – Aligns images and text in a shared space.  
- **DINO (Facebook AI)** – Self-supervised image embeddings.  

### **3️⃣ Graph Embeddings**
Used for link prediction, recommendation, and clustering in graphs.  
- **Node2Vec** – Learns vector representations for graph nodes.  
- **GraphSAGE** – Aggregates neighborhood data for embeddings.  
- **DeepWalk** – Uses random walks to generate graph embeddings.  

### **4️⃣ Recommendation System Embeddings**
Used for user-item interaction modeling and ranking.  
- **LightFM** – Hybrid model for recommendation systems.  
- **DeepFM** – Uses deep learning for sparse categorical features.  

### **5️⃣ Multimodal Embeddings**
Used for learning representations across different data types (e.g., text and images).  
- **CLIP (OpenAI)** – Learns joint embeddings for images and text.  
- **ALIGN (Google)** – Aligns vision and language in a shared space.  

These models help improve various AI-driven applications, from **search engines** to **chatbots** and **content recommendations**. 🚀  
