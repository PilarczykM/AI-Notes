{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "SENTENCES_FILE = Path(\"sentences.csv\")\n",
    "\n",
    "if not SENTENCES_FILE.exists():\n",
    "    print(\"sentences.csv file not found.\")\n",
    "    exit(1)\n",
    "\n",
    "dataset = pd.read_csv(SENTENCES_FILE)\n",
    "dataset.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate embedding using Open AI, but with free Ollama local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/v1\"\n",
    "EMBEDDED_SENTENCES_FILE = Path(\"embedded_sentences.csv\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=OLLAMA_URL,\n",
    "    api_key='ollama' # Required for the OpenAI API, but not for OLLAMA\n",
    ")\n",
    "\n",
    "def get_embeddings(sentence: str) -> list[float]:\n",
    "    response = client.embeddings.create(\n",
    "        model=\"nomic-embed-text:latest\",\n",
    "        input=sentence\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    return embedding\n",
    "\n",
    "if not EMBEDDED_SENTENCES_FILE.exists():\n",
    "    dataset[\"embedding\"] = dataset.sentence.apply(get_embeddings)\n",
    "    dataset.to_csv(EMBEDDED_SENTENCES_FILE, index=False)\n",
    "else:\n",
    "    dataset = pd.read_csv(EMBEDDED_SENTENCES_FILE)\n",
    "    dataset[\"embedding\"] = dataset.embedding.apply(eval).apply(np.array)\n",
    "\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"id\"] = range(1, len(dataset) + 1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dimensions of embedding line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = len(dataset.iloc[0][\"embedding\"])\n",
    "embedding_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAISS - Facebook library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "Check [Faiss Indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(dataset.embedding.to_list())\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I love soccer\"\n",
    "query_embedding = get_embeddings(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndexFlatL2 - Exact Search for L2 algorithm\n",
    "> The more documents you have got the slower it gets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faiss import IndexFlatL2, IndexIVFFlat, IndexIVFPQ\n",
    "\n",
    "index_l2 = IndexFlatL2(embedding_dimension)\n",
    "index_l2.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_l2.add(embeddings)\n",
    "index_l2.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, document_index = index_l2.search(np.expand_dims(query_embedding, axis=0), k=5)\n",
    "dataset.iloc[document_index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndexIVFFlat - Inverted file with exact post-verification\n",
    "\n",
    "### Voronoi Diagram\n",
    "\n",
    "Any point within a cell of the Voronoi diagram is closest to the centroid (center) associated with that cell.\n",
    "\n",
    "A Voronoi diagram partitions space into regions based on the distance to a specific set of points, known as centers or generators.\n",
    "\n",
    "This algorithm allows you to efficiently find the nearest point to your search criteria without having to compare all possible embeddingsâ€”only the closest region needs to be considered.\n",
    "\n",
    "![](./images/ivf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_centroids = 20\n",
    "quantizer = IndexFlatL2(embedding_dimension)\n",
    "index_ivf = IndexIVFFlat(quantizer, embedding_dimension, n_centroids)\n",
    "index_ivf.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ivf.train(embeddings)\n",
    "index_ivf.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ivf.add(embeddings)\n",
    "index_ivf.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, document_index = index_ivf.search(np.expand_dims(query_embedding, axis=0), k=5)\n",
    "dataset.iloc[document_index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using nprobe we can extend searching by looking into neighbors of found cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ivf.nprobe = 5\n",
    "_, document_index = index_ivf.search(np.expand_dims(query_embedding, axis=0), k=5)\n",
    "dataset.iloc[document_index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final optimization\n",
    "## IndexIVFPQ - IFV + Product Quantizer (PQ)\n",
    "\n",
    "![ndexIVFPQ - IFV + Product Quantizer (PQ)](./images/ivf-pq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_size = 8\n",
    "bits_per_centroid = 4\n",
    "\n",
    "index_ifv_pq = IndexIVFPQ(quantizer, embedding_dimension, n_centroids, code_size, bits_per_centroid)\n",
    "\n",
    "index_ifv_pq.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ifv_pq.train(embeddings)\n",
    "index_ifv_pq.add(embeddings)\n",
    "index_ifv_pq.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ifv_pq.nprobe = 5\n",
    "_, document_index = index_ifv_pq.search(np.expand_dims(query_embedding, axis=0), k=5)\n",
    "dataset.iloc[document_index[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
